# Experience 

---

## Meta - Software Engineering Intern, Machine Learning Components Team
### 06/2022 – 08/2022
*	Created tool to launch distributed deep learning model inference on CPU, GPU and custom accelerator machines. Supported models exceeding 200gb in size.
*	Created benchmark analysis tooling for other machine learning inference pipelines. Included storing and writing data to SQL databases and retrieving information using custom Python classes.
*	Added CPU and GPU utilization profiling for machine learning inference pipelines.
*	Used my benchmarking and hardware profiling tools to discover optimal model and pipeline configurations to achieve ~1.5x speedup on revenue critical recommender system model.

---

## Harvard University Lichtman Lab - Research Assistant
### 10/2020 – 09/2021 
*	Co-authored a paper [(link)](https://www.biorxiv.org/content/10.1101/2021.05.29.446289v4.abstract)
that presents the largest and most detailed connectomic reconstruction of human brain tissue conducted to date. Currently has over 80 citations.
*	Used RANSAC regression, SVM models and other machine learning techniques to create a novel way of categorizing brain cells into different cortical layers.
*	Used a combination of Python and C++ to analyse motifs and multi-node structures present in brain tissue using techniques from graph theory including the Kavosh algorithm.

---

## Stochastic Inc - Software Engineer
### 09/2020 – 09/2021 
*	During a leave from Harvard, worked for a year as a full time Software Engineer at Stochastic Inc, a company that specializes in compressing and accelerating machine learning models.
*	Implemented collapsed Gibbs sampling using C++ that simulated custom FPGA hardware.
*	Co-authored paper [(link)](https://ieeexplore.ieee.org/abstract/document/9773265) on Markov Chain Monte Carlo accelerators, presented at HPCA Conference.
*	Created a Python package for accelerating transformer models using attention-head pruning, integer quantization and optimized runtimes (using Pytorch and ONNX).
*	Worked on a web application that utilized the above natural language processing library. Used fastAPI backend that accepted transformer models and returned an optimized model to the user.
*	Used scikit-learn and custom Latent Dirichlet Allocation (LDA) package to create sentiment analysis pipeline that achieved state of the art accuracies with sparsely labelled data.
*	Managed two summer interns.

---

## Stochastic Inc - Software Engineering Intern
### 05/2020 – 09/2020 
*	Used C++ to write optimized LDA algorithm.
*	Used Boost Python to wrap C++ code in a Python package and Docker for easier customer use.
*	Benchmarked LDA package performance on various AWS EC2 instances and achieved state-of-the-art run times, beating competitors such as Gensim and MALLET by significant margins.
*	Work led to being offered a full time position in the 2020 – 2021 academic year.

---

## Harvard University - CS50 Teaching Fellow  
### 09/2021 – 12/2021 
*	Helped teach CS50, an undergraduate computer science course covering a wide array of topics including coding in C, Python and SQL. 
*	Taught a weekly 2 hour seminar covering coding concepts to groups of ~20 students. 
*	Held weekly tutorials and office hours answering student questions and assisting with problem sets.

---

## CodeConnects - Coding Tutor 
### 06/2020 – 09/2020 
*	Tutored middle and high school students in Python. Covered topics varying from basic syntax to data structures and algorithms.



